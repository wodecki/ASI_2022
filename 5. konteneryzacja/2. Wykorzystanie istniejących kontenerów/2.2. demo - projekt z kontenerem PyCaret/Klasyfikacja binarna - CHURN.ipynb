{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796ec13c",
   "metadata": {},
   "source": [
    "# Identyfikacja klientów o wysokim ryzyku odejścia do konkurencji (CHURN)\n",
    "\n",
    "\n",
    "Jesteś analitykiem firmy telekomunikacyjnej. Twoim zadaniem jest opracowanie modelu identyfikującego klientów o wysokim ryzyku odejścia do konkurencji (CHURN) oraz ocena efektywności ekonomicznej jego wdrożenia.\n",
    "\n",
    "Aktualna sytuacja jest następująca:\n",
    "\n",
    "1. Na jednym kliencie mamy 700 USD marży.\n",
    "2. Klientowi, któremu kończy się niebawem umowa, oferujemy 100 USD dolarów zachęty (bonus), by z nami został. Nie wykorzystujemy w tym celu żadnego modelu.\n",
    "3. Koszt nawiązania takiego kontaktu (praca telemarketingu) wynosi 50 USD\n",
    "4. Nie każdy z klientów, do którego zadzwonimy, decyduje się na przedłużenie umowy: w takiej sytuacji ponosimy koszt 50 USD, nie wydajemy jednak 100 USD na bonus.\n",
    "\n",
    "Z działu sprzedaży otrzymałeś plik z następującymi danymi:\n",
    "\n",
    "**State**: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "\n",
    "**Area Code**: the three-digit area code of the corresponding customer’s phone number\n",
    "\n",
    "**Phone**: the remaining seven-digit phone number\n",
    "\n",
    "**Account Length**: the number of days that this account has been active\n",
    "\n",
    "**Int’l Plan**: whether the customer has an international calling plan\n",
    "\n",
    "**VMail Plan**: whether the customer has a voice mail feature\n",
    "\n",
    "**VMail Message**: presumably the average number of voice mail messages per month\n",
    "\n",
    "**Day Mins**: the total number of calling minutes used during the day\n",
    "\n",
    "**Day Calls**: the total number of calls placed during the day\n",
    "\n",
    "**Day Charge**: the billed cost of daytime calls\n",
    "\n",
    "**Eve Mins, Eve Calls, Eve Charge**: the billed time, # of calls and cost for calls placed during the evening\n",
    "\n",
    "**Night Mins, Night Calls, Night Charge**: the billed time, # of calls and cost for calls placed during nighttime\n",
    "\n",
    "**Intl Mins, Intl Calls, Intl Charge**: the billed time, # of calls and cost for international calls\n",
    "\n",
    "**CustServ Calls**: the number of calls placed to Customer Service\n",
    "\n",
    "**Churn?**: whether the customer left. 0: stayed (no churn), 1: left (churn)\n",
    "\n",
    "Powodzenia!\n",
    "---\n",
    "\n",
    "Uwaga 1: tutorial ten jest adaptacją tutoriala dostępnego tutaj: https://www.pycaret.org/tutorials/html/CLF101.html \n",
    "\n",
    "Uwaga 2: dane źródłowe są dostępne np. tutaj://sagemaker-examples.readthedocs.io/en/latest/sagemaker_neo_compilation_jobs/xgboost_customer_churn/xgboost_customer_churn_neo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dd3e6",
   "metadata": {},
   "source": [
    "## Pozyskanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d41edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('customers_churn.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d21281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac82f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdźmy kształt danych\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyodrębnijmy zbiór testujący (dane te wykorzystamy dopiero na końcu do ewaluacji ostatecznego modelu)\n",
    "data = dataset.sample(frac = 0.8)\n",
    "unseen_data = dataset.drop(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37878cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, unseen_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553df6d",
   "metadata": {},
   "source": [
    "## Konfiguracja środowiska PyCaret\n",
    "\n",
    "Funkcja `setup()` inicjalizuje środowisko w pycaret i tworzy sekwencję transformacji przygotowania danych do modelowania i uruchomienia.\n",
    "\n",
    "`setup()` musi być wywołana przed wykonaniem jakiejkolwiek innej funkcji w pycaret. Pobiera ona dwa obowiązkowe parametry: ramkę danych pandas i nazwę kolumny docelowej. Wszystkie inne parametry są opcjonalne i używane do dostosowania potoku przetwarzania wstępnego.\n",
    "\n",
    "Podczas wykonywania `setup()`, algorytm PyCaret automatycznie identyfikuje typy danych dla wszystkich cech na podstawie ich właściwości. Nie zawsze jednak typ danych jest zidentyfikowany poprawnie. Aby to uwzględnić, PyCaret wyświetla tabelę zawierającą cechy i ich typy danych po wykonaniu setup(). Jeśli wszystkie typy danych są poprawnie zidentyfikowane można nacisnąć `enter` aby kontynuować lub `quit` aby zakończyć eksperyment. \n",
    "\n",
    "Upewnienie się, że typy danych są poprawne ma fundamentalne znaczenie, ponieważ są one podstawą dla trenowania i ewaluacji modeli w PyCaret. Zadania te są wykonywane inaczej dla każdego typu danych, dlatego bardzo ważna jest poprawna identyfikacja typów zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc414cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_DKU_1 = setup(data = data, target = 'churn', train_size=0.8, imputation_type='iterative', ignore_features = ['phone'], session_id=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c3b8f",
   "metadata": {},
   "source": [
    "Po pomyślnym uruchomieniu `setup` wyświetla tabelę z kluczowymi informacjami. Większość z nich jest związana z potokiem wstępnego przetwarzania, z których najbardziej istotne są:\n",
    "\n",
    "**session_id** : Pseudolosowa liczba rozprowadzana jako ziarno we wszystkich funkcjach dla późniejszej odtwarzalności. Jeśli nie zostanie podany żaden `session_id`, automatycznie generowana jest liczba losowa, która jest dystrybuowana do wszystkich funkcji. W tym eksperymencie, `session_id` jest ustawiony jako 123 dla późniejszej odtwarzalności.\n",
    "\n",
    "**Target Type** : Binarny lub Wieloklasowy. Typ celu jest automatycznie wykrywany i pokazywany. Nie ma różnicy w sposobie wykonywania eksperymentu dla problemów Binarnych i Wieloklasowych. Wszystkie funkcje są identyczne.\n",
    "\n",
    "**Label Encoded** : Kiedy zmienna docelowa jest typu string (np. 'Tak' lub 'Nie') zamiast 1 lub 0, PyCaret automatycznie koduje etykietę na 1 i 0 i wyświetla mapowanie (0 : Nie, 1 : Tak). \n",
    "\n",
    "**Original Data** : Wyświetla oryginalny kształt zbioru danych. W tym eksperymencie (2666, 23) oznacza 2666 próbek i 23 cechy, w tym kolumnę docelową.\n",
    "\n",
    "**Missing Values** : Jeśli w oryginalnych danych brakuje wartości, zostanie to wyświetlone jako `True`. Dla tego eksperymentu nie ma brakujących wartości w zbiorze danych.\n",
    "\n",
    "**Numeric Features** : Liczba cech zidentyfikowanych jako numeryczne. W tym zestawie danych, 15 z 21 cech jest wnioskowanych jako numeryczne.\n",
    "\n",
    "**Categorical Features** : Liczba cech zidentyfikawanych jako kategoryczne. W tym zbiorze danych, 6 z 21 cech jest określanych jako kategoryczne.\n",
    "\n",
    "**Transformed Train Set** : Wyświetla kształt przekształconego zbioru treningowego. Zauważ, że oryginalny kształt (2666, 23) jest przekształcony do (2132, 96) dla przekształconego zbioru treningowego, a liczba cech wzrosła do 96 z 23 z powodu kodowania.\n",
    "\n",
    "**Transformed Test Set** : Wyświetla kształt przekształconego zbioru testowego/hold-out. W zbiorze testowym znajduje się 534 próbek. Podział ten przeprowadzony jest w domyślnej proporcji 70/30, która może być zmieniona przy pomocy parametru `train_size` w `setup`ie.\n",
    "\n",
    "Zauważ, że kilka zadań, które są niezbędne do przeprowadzenia modelowania, jest realizowanych automatycznie, np. imputacja brakujących wartości (w tym przypadku nie ma brakujących wartości w danych treningowych, ale nadal potrzebujemy imputatorów dla niewidzianych danych), kodowanie kategorialne itp. Większość parametrów w setup() jest opcjonalna i używana do dostosowywania potoku wstępnego przetwarzania. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28436b16",
   "metadata": {},
   "source": [
    "## Eksploracyjna analiza danych (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a47157",
   "metadata": {},
   "source": [
    "Eksploracyjna analiza danych możliwa jest w PyCaret dzięki funkcji `eda()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0c6f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29113e67",
   "metadata": {},
   "source": [
    "Do Eksploracyjnej Analizy Danych (EDA) możemy też użyć modułu Pandas Profiling. Więcej szczegółów można znaleźć na stronie: https://github.com/pandas-profiling/pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e672e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(dataset, title=\"Pandas Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fef34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b7da4",
   "metadata": {},
   "source": [
    "## Trening i porównanie modeli\n",
    "\n",
    "Na początku procesu modelowania zalecane jest porównanie najprostszych wersji wszystkich modeli bazowych w celu oceny ich jakości (chyba że dokładnie wiesz, jakiego modelu potrzebujesz). \n",
    "\n",
    "Funkcja `compare_models` trenuje wszystkie modele z biblioteki i ocenia je przy użyciu walidacji krzyżowej. \n",
    "\n",
    "Efektem jest tabela wyników, która pokazuje średnią Accuracy, AUC, Recall, Precyzję, F1, Kappa i MCC dla wszystkich warstw (domyślnie 10) wraz z czasami treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = compare_models(sort = 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df87a3b",
   "metadata": {},
   "source": [
    "Uruchomienie jednej komendy umożliwiło trening i ewaluację ponad 15 modeli. Tabela wyników wyświetlona powyżej zaznacza najwyższe wyniki metryki tylko dla celów porównawczych. Tabela domyślnie posortowana jest wg 'Accuracy' (od najwyższej do najniższej), ale można to zmienić poprzez podanie parametru sortowania. Przykładowo: `compare_models(sort = 'AUC')` posortuje siatkę według AUC zamiast Accuracy. \n",
    "\n",
    "Jeśli chcesz zmienić parametr `fold` z domyślnej wartości 10 na inną wartość, możesz użyć parametru `fold`. Przykładowo, `compare_models(fold = 5)` porówna wszystkie modele w procesie 5-krotnej walidacji krzyżowej. Zmniejszenie liczby warstw poprawi czas treningu. Domyślnie, `compare_models` zwraca najlepiej działający model w oparciu o domyślną kolejność sortowania, ale może być użyty do zwrócenia listy N najlepszych modeli poprzez użycie parametru `n_select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a6318",
   "metadata": {},
   "source": [
    "## Tworzenie i optymalizacja najlepszego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10887f9",
   "metadata": {},
   "source": [
    "### Stworzenie modelu\n",
    "`Create_model` jest najbardziej szczegółową funkcją w PyCaret i często podstawą większości funkcjonalności PyCaret. Jak sama nazwa wskazuje, funkcja ta trenuje i ocenia model używając walidacji krzyżowej, którą można skonfigurować za pomocą parametru `fold`. Na wyjściu wypisuje tabelę wyników, która pokazuje Accuracy, AUC, Recall, Precision, F1, Kappa i MCC w zależności od liczby warstw.\n",
    "\n",
    "W pozostałej części tego poradnika będziemy pracować z modelem `dt` (Decision Tree Classifier): praktycznie zwycięskim w kategorii Recall, niemniej z interesującym potencjałym udoskonalenia.\n",
    "\n",
    "W bibliotece modeli PyCaret dostępnych jest 18 modeli klasyfikacyjnych. Aby zobaczyć listę wszystkich klasyfikatorów można użyć funkcji `models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce241a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = create_model('dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65248c20",
   "metadata": {},
   "source": [
    "Zauważ, że średni wynik wszystkich modeli zgadza się z wynikiem wypisanym w `compare_models()`. Dzieje się tak dlatego, że metryka wypisana w siatce wyników `compare_models()` jest średnią wyników dla wszystkich warstw walidacji krzyżowej (CV). \n",
    "\n",
    "Podobnie jak w przypadku `compare_models()`, jeśli chcesz zmienić parametr `fold` z domyślnej wartości 10 na inną wartość, możesz użyć parametru `fold`. Przykładowo, `create_model('dt', fold = 5)` utworzy klasyfikator drzewa decyzyjnego używając 5-krotnego warstwowego CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ead0e",
   "metadata": {},
   "source": [
    "## Interaktywna analiza modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e600d79",
   "metadata": {},
   "source": [
    "PyCaret umożliwia kompleksową, interaktywną analizę wytrenowanego modelu, z wykorzystaniem funkcji `dashboard()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36931963",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a66a6",
   "metadata": {},
   "source": [
    "Funkcja `check_fairness` umożliwia sprawdzenie, czy w wyniku modelowania któraś z grup nie jest dyskryminowana. Pozwala porównać pod tym kątem różne sub-populacje. Porównaj: https://github.com/fairlearn/fairlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21b359",
   "metadata": {},
   "source": [
    "### Udoskonalenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3247356",
   "metadata": {},
   "source": [
    "Tworząc model przy użyciu funkcji `create_model()`, PyCaret używa domyślnych hiperparametrów do trenowania modelu. W celu dostrojenia hiperparametrów używana jest funkcja `tune_model()`. Funkcja ta automatycznie dostraja hiperparametry modelu używając `Random Grid Search` na wcześniej zdefiniowanej przestrzeni poszukiwań. \n",
    "\n",
    "Na wyjściu wypisywana jest tabela wyników, która pokazuje Accuracy, AUC, Recall, Precyzję, F1, Kappa i MCC dla najlepszego modelu. Aby użyć niestandardowej siatki wyszukiwania, możesz przekazać parametr `custom_grid` w funkcji `tune_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt = tune_model(dt, optimize='Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511556c",
   "metadata": {},
   "source": [
    "Domyślnie, `tune_model` optymalizuje Accuract, ale można to zmienić używając parametru `optimize`. Na przykład: `tune_model(dt, optimize = 'AUC')` będzie szukał takich hiperparametrów klasyfikatora drzewa decyzyjnego, które dają najwyższy wynik AUC zamiast Accuracy. W naszym przykładzie wykorzystaliśmy Recall ze względu na specyfikę problemu (analiza CHURN).\n",
    "\n",
    "Generalnie, gdy zbiór danych jest niezrównoważony (jak np. zbiór danych kredytowych, z którym pracujemy), Accuracy nie jest dobrą metryką do rozważenia. Metodologia stojąca za wyborem właściwej metryki do oceny klasyfikatora wykracza poza zakres tego tutoriala, ale jeśli chcesz dowiedzieć się więcej na ten temat, możesz spojrzeć np. tutaj (https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb5c95",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75e15d",
   "metadata": {},
   "source": [
    "### Wykresy\n",
    "\n",
    "Przed finalizacją modelu, warto wykorzystać funkcję `plot_model()` do analizy wydajności w różnych wymiarach, takich jak AUC, confusion_matrix, granica decyzji itp.\n",
    "\n",
    "Dostępnych jest 15 różnych wykresów - aby zobaczyć ich listę, sprawdź dokumentację `plot_model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3a0a0",
   "metadata": {},
   "source": [
    "#### Macierz pomyłek (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_model(tuned_dt, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab3734",
   "metadata": {},
   "source": [
    "#### AUC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_dt, plot = 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a46ba6",
   "metadata": {},
   "source": [
    "#### Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63bbec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_dt, plot = 'pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1858d3",
   "metadata": {},
   "source": [
    "#### Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_dt, plot = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33fbe4",
   "metadata": {},
   "source": [
    "Innym sposobem na analizę wydajności modeli jest użycie funkcji `evaluate_model()`, która wyświetla interfejs użytkownika dla wszystkich dostępnych wykresów dla danego modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abc628",
   "metadata": {},
   "source": [
    "### Optymalizacja progu (threshold)\n",
    "\n",
    "PyCaret pozwala też na optymalizację progu w klasyfikacji binarnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08aaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_threshold(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94b635",
   "metadata": {},
   "source": [
    "## Predykcja na zbiorze testowym/hold-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65b1fe",
   "metadata": {},
   "source": [
    "Przed sfinalizowaniem modelu, zalecane jest wykonanie testu efektywności modelu na zbiorze testowym/hold-out.\n",
    "\n",
    "Jeśli spojrzysz na tabelę wyników w części `setup` powyżej, zobaczysz, że 20% (534 próbki) danych zostało wyodrębnione jako próbka testowa/hold-out. Wszystkie metryki oceny, które widzieliśmy powyżej to wyniki walidacji krzyżowej oparte tylko na zestawie treningowym (80%). \n",
    "\n",
    "W tym momencie, używając naszego ostatecznego wytrenowanego modelu przechowywanego w zmiennej `tuned_dt`, sprawdzimy wyniki predykcji (i ich metryki) na zbiorze testowym i zobaczymy, na ile różnią się one od wyników walidacji krzyżowej w procesie trenowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c388ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdb51b",
   "metadata": {},
   "source": [
    "Jak widać, w procesie trenowania otrzymaliśmy Recall na poziomie 0.8076, zaś na zbiorze testowym nieco lepszy wynik: 0.8485."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452006c6",
   "metadata": {},
   "source": [
    "## Udostępnienie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035e757",
   "metadata": {},
   "source": [
    "Ostatnim etapem naszego eksperymentu jest finalizacja modelu.\n",
    "\n",
    "Typowy proces uczenia maszynowego w PyCaret zaczyna się od `setup()`, po którym następuje porównanie wszystkich modeli przy użyciu `compare_models()` i wybranie kilku modeli najlepiej rokujących (w oparciu o interesującą nas metrykę), a następnie ich udoskonalenie np. poprzez poprzez optymalizację hiperparametrów, ensembling, stacking itp. \n",
    "\n",
    "Taki proces ostatecznie prowadzi do najlepszego modelu, który możesz wykorzystać w środowisku produkcyjnym do do przewidywań na nowych, nieznanych danych. \n",
    "\n",
    "Funkcja `finalize_model()` dopasowuje model do całego zbioru danych, włączając w to próbkę testową (w tym przypadku 30%).\n",
    "\n",
    "Jej celem jest wytrenowanie modelu na kompletnym zbiorze danych, zanim zostanie on wdrożony do produkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dt = finalize_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79343403",
   "metadata": {},
   "source": [
    "Uwaga\n",
    "___\n",
    "Podczas finalizacji z wykorzystaniem `finalize_model()` do trenowania modelu wykorzystywany jest cały zbiór danych (czyli treningowy i testowy).\n",
    "\n",
    "W efekcie, sprawdzanie tego modelu na zbiorze testowym/hold'out nie ma sensu (jest mylące): dane były dostępne podczas trenowania. \n",
    "\n",
    "W przykładzie poniżej wykorzystamy funkcję `predict_model` do oceny modelu zfinalizowanego `final_dt`. Jak się domyślasz, wyniki oceny będzie lepszy niż poprzednio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27278038",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(final_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450bad7",
   "metadata": {},
   "source": [
    "Zwróć uwagę, że `Recall` w `final_dt` wzrósł z 0.8485 do poziomu 0.8636 mimo tego, że model jest taki sam. Dzieje się tak, ponieważ model `final_dt` został wytrenowany na pełnym zbiorze danych, w tym na zbiorze testowym/hold-out. **Jeszcze raz: pamiętaj, że operacja ta daje mylące wyniki!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df10c6",
   "metadata": {},
   "source": [
    "### Predykcja nieznanych danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef3aa2",
   "metadata": {},
   "source": [
    "Funkcja `predict_model()` może być wykorzystana do predykcji na nieznanym zbiorze danych. Jedyną różnicą w stosunku do czynności realizowanych powyżej jest to, że tym razem przekażemy parametr `unseen_data` z linii 7. \n",
    "\n",
    "Parametr `unseen_data` jest zmienną utworzoną na początku tutoriala i zawiera 5% (1200 próbek) oryginalnego zbioru danych, który nigdy nie był udostępniony PyCaret na potrzeby trenowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(final_dt, data=unseen_data)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8ba0d",
   "metadata": {},
   "source": [
    "Efektem uruchomienia `predict_model` jest dodanie do zbioru `unseen_data` kolumn `Label` i `Score` zawierających odpowiednio predykcję i jej prawdopodobieństwo. \n",
    "\n",
    "Zauważ, że przewidywane wyniki są stosowane do oryginalnego zbioru danych, podczas gdy wszystkie transformacje danych są automatycznie wykonywane w tle. \n",
    "\n",
    "Mając te kolumny możesz też sprawdzić metryki jakości modelu korzystając z modułu `pycaret.utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f46430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.utils import check_metric\n",
    "check_metric(unseen_predictions['churn'], unseen_predictions['Label'], metric = 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f788de",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metric(unseen_predictions['churn'], unseen_predictions['Label'], metric = 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2c8d9",
   "metadata": {},
   "source": [
    "### Zapis modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541e84d",
   "metadata": {},
   "source": [
    "Finalizacja modelu `tuned_dt`, zapisana w `final_dt`, kończy proces modelowania.\n",
    "\n",
    "Pojawia się jednak pytanie: w jaki sposób zrobić predykcję na zupełnie nowych danych, np. w systemie produkcyjnym? W szczególności, czy będziemy musieli ponownie poddawać te dane transformacjom takim, jak w procesie modelowania?\n",
    "\n",
    "Odpowiedź brzmi nie: wbudowana w PyCaret funkcja `save_model()` pozwala na zapisanie modelu wraz z całym potokiem transformacji do późniejszego wykorzystania na produkcji. Poniżej zapiszemy nasz cały potok do pliku `Final Decision Tree Model Dec2021`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d985375",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(final_dt,'Final Decision Tree Model Jan2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa6311",
   "metadata": {},
   "source": [
    "### Wczytanie zapisanego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663ab71",
   "metadata": {},
   "source": [
    "Aby załadować zapisany model np. na innym komputerze lub środowisku produkcyjnym, użyjemy funkcji `load_model()`. Następnie w prosty sposób zastosowalibyśmy zapisany model na nowych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bf971",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_final_dt = load_model('Final Decision Tree Model Jan2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931b548",
   "metadata": {},
   "source": [
    "Tak wczytany model możesz po prostu użyć do przewidywania na nowych danych używając tej samej funkcji `predict_model()`. Poniżej zastosujemy go do przewidywania tych samych `data_unseen`, których użyliśmy w sekcji powyżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = pd.read_csv('customers_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = predict_model(saved_final_dt, data=unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b6a83",
   "metadata": {},
   "source": [
    "# Stworzenie aplikacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def5f18",
   "metadata": {},
   "source": [
    "PyCaret umożliwia uruchomienie prostej aplikacji serwującej model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_app(saved_final_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a6dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
